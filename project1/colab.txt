{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from transformers import AutoImageProcessor, ViTImageProcessor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import datasets\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import TFViTForImageClassification, create_optimizer, TFCvtForImageClassification\n",
    "from transformers import CvtConfig, CvtModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_image_folder_dataset(root_path):\n",
    "    \"\"\"creates `Dataset` from image folder structure\"\"\"\n",
    "\n",
    "    # get class names by folders names\n",
    "    _CLASS_NAMES = os.listdir(root_path)\n",
    "    # defines `datasets` features`\n",
    "    features = datasets.Features({\n",
    "        \"img\": datasets.Image(),\n",
    "        \"label\": datasets.features.ClassLabel(names=_CLASS_NAMES),\n",
    "    })\n",
    "    # temp list holding datapoints for creation\n",
    "    img_data_files = []\n",
    "    label_data_files = []\n",
    "    # load images into list for creation\n",
    "    for img_class in os.listdir(root_path):\n",
    "        for img in os.listdir(os.path.join(root_path, img_class)):\n",
    "            path_ = os.path.join(root_path, img_class, img)\n",
    "            img_data_files.append(path_)\n",
    "            label_data_files.append(img_class)\n",
    "    # create dataset\n",
    "    ds = datasets.Dataset.from_dict({\"img\": img_data_files, \"label\": label_data_files}, features=features)\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_imgs = create_image_folder_dataset(\"drive/MyDrive/project1/train\")\n",
    "img_class_labels = train_imgs.features[\"label\"].names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_id = \"google/vit-base-patch16-224-in21k\"\n",
    "#model_id = \"microsoft/cvt-13\"\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(model_id)\n",
    "#feature_extractor.size = {\"shortest_edge\":512,}\n",
    "# learn more about data augmentation here: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.2, fill_mode=\"constant\", fill_value=0),\n",
    "        layers.RandomBrightness(factor=0.2),\n",
    "        layers.RandomContrast(factor=0.2)\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# use keras image data augementation processing\n",
    "def augmentation(examples):\n",
    "    inputs = feature_extractor([tf.keras.preprocessing.image.array_to_img(data_augmentation(img)) for img in examples['img']])\n",
    "    inputs[\"labels\"] = examples[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# basic processing (only resizing)\n",
    "def process(examples):\n",
    "    inputs = feature_extractor(examples['img'])\n",
    "    inputs[\"labels\"] = examples[\"label\"]\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_size = .1\n",
    "train_val_set = train_imgs.train_test_split(test_size=test_size)\n",
    "train_val_set[\"test\"] = train_val_set[\"test\"].with_transform(process)\n",
    "train_val_set[\"train\"] = datasets.concatenate_datasets([train_val_set[\"train\"], train_val_set[\"train\"], train_val_set[\"train\"]]).with_transform(augmentation)\n",
    "#train_val_set[\"train\"] = train_val_set[\"train\"].with_transform(augmentation)\n",
    "\n",
    "from transformers import TFViTForImageClassification\n",
    "\n",
    "labels = train_val_set['train'].features['label'].names\n",
    "\n",
    "model = TFViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ")\n",
    "\n",
    "#model = TFCvtForImageClassification.from_pretrained(\n",
    "#    model_id,\n",
    "#    )\n",
    "#model.classifier = tf.keras.layers.Dense(5)\n",
    "#model.num_labels = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_train_epochs = 5\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "learning_rate = 0.00003\n",
    "weight_decay_rate = 0.01\n",
    "num_warmup_steps = 0\n",
    "output_dir = model_id.split(\"/\")[1]\n",
    "hub_model_id = f'{model_id.split(\"/\")[1]}-eyes'\n",
    "fp16 = True\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = train_val_set[\"train\"].to_tf_dataset(\n",
    "    columns=['pixel_values'],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=data_collator)\n",
    "\n",
    "# converting our test dataset to tf.data.Dataset\n",
    "tf_eval_dataset = train_val_set[\"test\"].to_tf_dataset(\n",
    "    columns=['pixel_values'],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=eval_batch_size,\n",
    "    collate_fn=data_collator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class model_per_epoch(keras.callbacks.Callback):\n",
    "    def __init__(self, model,filepath,save_best_only):\n",
    "        self.filepath=filepath\n",
    "        self.model=model\n",
    "        self.save_best_only=save_best_only\n",
    "        self.lowest_loss=np.inf\n",
    "        self.best_weights=self.model.get_weights()\n",
    "    def on_epoch_end(self,epoch, logs=None):\n",
    "        v_loss=logs.get('val_loss')\n",
    "        if v_loss< self.lowest_loss:\n",
    "            self.lowest_loss =v_loss\n",
    "            self.best_weights=self.model.get_weights()\n",
    "            self.best_epoch=epoch +1\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            name= str(self.best_epoch) +'-' + str(self.lowest_loss)[:str(self.lowest_loss).rfind('.')+3] + '.h5'\n",
    "            file_id=os.path.join(self.filepath, name)\n",
    "            self.model.save_weights(file_id)\n",
    "        if self.save_best_only==False:\n",
    "            name= str(epoch) +'-' + str(v_loss)[:str(v_loss).rfind('.')+3] + '.h5'\n",
    "            file_id=os.path.join(self.filepath, name)\n",
    "            self.model.save(file_id)\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.save_best_only == True:\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            name= str(self.best_epoch) +'-' + str(self.lowest_loss)[:str(self.lowest_loss).rfind('.')+3] + '.h5'\n",
    "            file_id=os.path.join(self.filepath, name)\n",
    "            self.model.save_weights(file_id)\n",
    "            print(' model is returned with best weights from epoch ', self.best_epoch)\n",
    "\n",
    "save_dir=r'drive/MyDrive/project1/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=weight_decay_rate,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    ")\n",
    "\n",
    "# define metrics\n",
    "metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "]\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping(patience=0),\n",
    "           model_per_epoch(model, save_dir, True)]\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    tf_train_dataset.prefetch(5),\n",
    "    validation_data=tf_eval_dataset.prefetch(5),\n",
    "    callbacks=callbacks,\n",
    "    epochs=100,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_weights(\"drive/MyDrive/project1/transformer_weights.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
